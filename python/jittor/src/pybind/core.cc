// ***************************************************************
// Copyright (c) 2022 Jittor. All Rights Reserved. 
// Maintainers: Dun Liang <randonlang@gmail.com>. 
// This file is subject to the terms and conditions defined in
// file 'LICENSE.txt', which is part of this source code package.
// ***************************************************************
#include "core.h"
#include "grad.h"
#include "pyjt/py_obj_holder.h"
#include "init.h"
#include "pyjt/numpy.h"
#include "utils/seh.h"
#include "misc/cuda_flags.h"
#include "misc/opencl_flags.h"
namespace jittor {
DEFINE_FLAG(string, device_type, "auto", "auto/cuda/opencl");
DEFINE_FLAG_WITH_SETTER(int, use_device, 0,
    "Use device or not. 1 for trying to use device, 2 for forcing to use device.");
SEH_HOOK;

// Those function is generated by python
EXTERN_LIB void pyjt_def_all(PyObject* m);

vector<VarHolder*> _grad(VarHolder* loss, const vector<VarHolder*>& targets, bool retain_graph) {
   vector<Var*> vs;
   vs.reserve(targets.size());
   for (auto* v : targets) vs.push_back(v->var);
   auto grads = grad(loss->var, vs, retain_graph);
   vector<VarHolder*> grads_hold;
   grads_hold.reserve(targets.size());
   for (auto& grad : grads)
       grads_hold.push_back(new VarHolder(move(grad)));
   return grads_hold;
}

void setter_use_device(int value) {
    if (value) {
        if (device_type=="auto"){
            #ifdef HAS_CUDA
                use_cuda=1;
            #elif defined HAS_OPENCL
                use_opencl=1;
            #endif
            if (!use_cuda and !use_opencl) ASSERT(0);
        } else if (device_type=="cuda") {
            #ifdef HAS_CUDA
                use_cuda=1;
            #endif
            if (!use_cuda) ASSERT(0);
        } else if (device_type=="opencl") {
            #ifdef HAS_OPENCL
                use_opencl=1;
            #endif
            if (!use_opencl) ASSERT(0);
        } else ASSERT(0);
    }
}

} // jittor

static void init_module(PyModuleDef* mdef, PyObject* m) {
    mdef->m_doc = "Inner c++ core of jittor";
    jittor::init();
    jittor::numpy_init();
    jittor::pyjt_def_all(m);
}
PYJT_MODULE_INIT(jittor_core);
